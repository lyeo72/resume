### **DOCC 프로젝트: 엘라스틱서치에서 RDB로의 데이터 전환**

기간 : 2022.07 ~ 2022.09

**기술 스택 : Java, Spring, MariaDB, MyBatis, ElarsticSearch**

**프로젝트 개요: 병원에서 실제 사용하는 데이터를 시각화 하여 각 분과별로 나타냄**

**작업 내용:**

기존에 엘라스틱서치를 활용한 데이터 조회 시 간헐적으로 올바른 데이터를 반환하지 않는 문제가 발생하여,

이를 해결하기 위해 엘라스틱서치 데이터를 배치 처리를 통해 RDB에 적재하고, RDB에서 데이터를 조회하는 방식으로 변경하는 작업을 수행하였습니다.

**역할:**

기존에는 엘라스틱서치를 통해 데이터를 조회하던 방식을 RDB로 조회하는 방식으로 전환하여, 데이터의 일관성과 정확성을 확보하였습니다.

CT, 수술, 병상, 채혈, MRI, 외래 PAN 중 CT, 수술, 채혈 PAN의 api들을 DB 조회방식으로 변경하였습니다.

**과정:**

데이터 비대화로 인한 데이터 조회 성능 이슈가 발생했습니다.

특히, 채혈 데이터의 경우 한달 동안 약 198만 건의 데이터가 적재되었고 계속해서 누적되기 때문에 데이터 처리에 대한 성능 개선이 필요했습니다.

**해결방법:**

데이터 조회 성능을 향상시키기 위해 다음과 같은 접근 방법을 채택하였습니다:

- **운영지표 조회용 테이블 생성:** 매일 자정 0:01에 배치 작업을 실행하여 어제 날짜의 데이터를 처리하고, '날짜', '대기시간', '채혈환자수' 컬럼으로 구성된 조회용 테이블에 데이터를 가공하여 삽입합니다.
- **데이터 가공 및 적재:** 배치 작업을 통해 어제의 데이터를 적재 테이블에 가공하여 삽입합니다. 이러한 가공은 전일, 한달, 분기별 데이터를 적절히 처리하여 조회 성능을 향상시킵니다.
- **운영지표 조회 시 최적화:** 운영지표 조회 시에는 미리 생성한 조회용 테이블에서 데이터를 바로 조회하도록 변경하였습니다. 이렇게 함으로써 실시간 데이터 처리에 비해 훨씬 빠른 응답 시간을 제공가능합니다.

### **CDW**

기간: 2022.09 ~ 2022.11, 2023.06 ~ 2023. 08

**기술 스택:** Java, Spring, MariaDB, MyBatis

**프로젝트 개요:** 병원과 연계하여 병원의 저장 데이터를 의사결정 및 분석을 위한 데이터로 가공 및 추출을 지원하는 서비스를 개발하였습니다.

**역할:**

- **데이터 가공 API 개발 및 유지보수:**

 코호트 디스커버리 고도화 작업과 유지보수를 담당하였습니다. 이는 데이터 가공을 and 조건과 or 조건을 통해 간편하게 할 수 있는 Easy버전인 코호트 디스커버리의 작업을 포함하며, 가공한 데이터를 저장, 조회, 삭제, 공유 기능의 워크스페이스에서의 API 개발 및 유지보수를 담당하였습니다.

**성능 최적화와 쿼리 튜닝:**

기존 시스템에서는 특정 쿼리가 전체 테이블에 대한 풀 스캔(Full Table Scan)을 수행하여 처리 시간이 4초 이상 소요되고 있었습니다. 이 문제를 해결하기 위해 해당 테이블에 적절한 인덱스를 생성함으로써 쿼리 실행 시간을 0.7초로 크게 줄였습니다.

**코드 개선:**

**1. 파라미터 체크:**

- 기존의 회사 자체 프레임워크의 메서드를 이용한 서비스단에서 파라미터 검증을 하는 방식을 개선하였습니다. 이전 방식에서 발생했던 파라미터 누락 문제 및 예외 메시지의 고정성 문제를 해결하기 위해, 컨트롤러에서 요청을 받을 때 request 객체를 생성하여 파라미터를 동적으로 매핑시키는 방식으로 코드를 최적화하였습니다.

**2. 예외 처리:**

- 기존에는 하드코딩된 상태 코드와 메시지를 반환하는 방식에서, 커스텀 에러 객체와 ErrorHandler를 도입하여 동적인 예외 메시지를 클라이언트에게 반환함으로써 파라미터 문제에 대한 명확한 정보 전달과 유지보수 용이성을 확보하였습니다.

**장점 및 결과물:**

- **동적인 예외 메시지:** 파라미터 검증 시 발생한 예외에 대해 동적인 메시지를 생성하여 클라이언트에게 전달함으로써 문제 해결의 신속성과 정확성을 제공합니다.
- **코드 일관성:** 커스텀 에러 객체와 ErrorHandler를 사용함으로써 예외 처리 코드가 일관성을 갖게 되어 코드의 가독성과 유지보수성을 향상시켰습니다.

### **금융공통 프로젝트 (YYYY년 - YYYY년)**

기간 : 2022.11 ~ 2022.06

**기술 스택:** Java, SpringBoot, PostgreSQL, JPA, Redis

**프로젝트 개요:**
더존비즈온의 비즈니스플랫폼 위에서 신한은행과 연계하여 금융서비스를 제공하는 금융플랫폼으로 진입하는 관문서비스입니다. 이 프로젝트는 위하고 서비스 별로 금융서비스의 접근 권한 및 서비스 가입 관리 등의 로직을 담당하고 있습니다.

**역할 및 책임:**

- 원격 서비스 간 통신을 위한 FeignClient 도입 및 관리 담당.
- **Custom ErrorDecoder 구현:** 외부 API 호출 시 발생하는 다양한 에러 상황에 대응하기 위해 Feign의 ErrorDecoder를 커스터마이징하여 예외 처리 및 로깅을 담당했습니다.

개선방향**:**

초기에는 외부 API 응답의 다양한 에러 상태 코드와 메시지를 효과적으로 처리하고 분류하는 것이 어려웠습니다. 특히, 외부 서비스마다 에러 응답의 형식과 규칙이 다르다는 점이 복잡도를 높였습니다.

- **해결 방법:**
    - **에러 상태 코드 표준화:** 외부 서비스들의 다양한 응답을 표준 상태 코드로 매핑하여 일관된 에러 처리를 할 수 있도록 표준화 작업을 진행했습니다.
    - **상세 에러 메시지 추출:** Feign의 ErrorDecoder를 이용하여 외부 응답에서 상세 에러 메시지를 추출하고, 이를 기반으로 예외 유형을 동적으로 할당하는 방식으로 다양한 상황에 대응했습니다.

### 외상매출금입금확인 **서비스 가입 로직 개발**

**프로젝트 개요:**
서비스 가입시 여러 사용자가 동시에 가입을 시도할 때 중복 호출로 인한 문제를 방지하고 안정적인 서비스 운영을 위해 Redis 기반의 분산락을 구현하기 위해 Redission 라이브러리를 활용하였습니다.

**개발 내용:**

- **동시성 문제 해결을 위한 Redisson 분산락 도입:**
    - 여러 사용자가 동시에 가입을 시도할 때 동시성 문제가 발생할 수 있습니다. Redission을 사용하여 Redis 기반의 분산락을 구현함으로써 가입 신청 API의 중복 호출을 방지하고 데이터의 일관성을 유지하였습니다.
- **성능 최적화 및 안정성 확보:**
    - Redisson의 분산락을 효과적으로 활용하여 안정된 성능을 유지하였습니다. 또한, 트랜잭션과 잠금 기능을 적절히 조절하여 안전하게 동시성을 관리하였습니다.
    

### **가명화 도구 프로젝트**

기간 : 2023.08~ 2023.11

**기술 스택:** Java, Spring, MyBatis, MariaDB

**작업 내용:**
이 프로젝트는 CDW 서비스와 연동하여 가공된 데이터셋의 정보를 일반인이 알아볼 수 없는 수준으로 가명화 처리를 제공.

역할

**AOP를 활용한 공통화 처리:**

- **도입 배경**
    - 가명화 모듈이 20개 이상으로 각 api 에서 세션을 관리하고 요청 시 함께 보내는 것은 유지보수에 어려움을 초래하고 코드 중복과 복잡성을 야기했습니다.
- **AOP 도입과 작업 내용:**
    - AOP(Aspect-Oriented Programming)를 활용하여 세션 관리와 요청 처리를 공통화하였습니다. 이를 통해 코드 중복을 최소화하고 유지보수성을 향상시켰습니다.

**결과와 이점:**

- **코드 중복 제거:**
    - 각 서비스에서 세션 관리와 요청 처리를 할 필요가 없어져서 코드 중복을 최소화하였습니다. 이로 인해 유지보수성이 향상되었습니다.
- **가명화 모듈 확장성 향상:**
    - 새로운 가명화 모듈을 추가하더라도 AOP에서의 공통 로직만 업데이트하면 되므로 쉽게 확장 가능해졌습니다.

문제사항
데이터 진입시점에서 신규 데이터와 기존 저장된 데이터를 구분하여 처리하는 로직에서, 메타데이터가 300개 이상으로 늘어남에 따라 속도 저하가 발생하였습니다. 기존 방식은 각 데이터를 하나씩 적재하고 있었으나, 이 방식은 데이터의 양이 많아지면서 성능 문제를 초래하게 되었습니다.

**개선 과정:**

- **기존 방식 분석:**
    - 기존에는 DB 저장 정보, 표본데이터, 테이블명세서 정보를 각각 조회하고 이를 조합하여 적재하는 방식을 사용하고 있었습니다. 이 방식은 데이터의 양이 많아지면서 DB와의 통신이 많아져 성능 문제를 야기하게 되었습니다.
- **벌크 적재 방식 도입:**
    - 성능 문제를 해결하기 위해 최초 접근시 벌크 적재(Bulk Insert) 방식을 도입하였습니다. DB 저장 정보, 표본데이터, 테이블명세서 정보를 한 번에 조회하여 적재하는 방식으로 변경하였습니다.
